poc_design_gpts_visual_expression_flow:
  title: "非侵襲的プロフィール抽出フロー（対話＋描画連動）"
  purpose: >
    障がい当事者に対して、意図を明示せずに認知・非認知能力や情緒傾向を把握するための
    GPTsとの自然な対話誘導と、iPad等を用いた非言語的描画指示を組み合わせた記録型PoCモデル。

  target_user:
    - 認知的評価や自己申告に抵抗・困難を感じる支援対象者
    - 発語が難しいが、表現意欲のある当事者
    - 「描く」ことが得意または反応が出やすいと見られる当事者

  device_roles:
    - note_pc: "GPTsとのチャット対話専用（自然言語プロンプトによる誘導）"
    - tablet: "iPad等を使用し、非言語的表現（絵・色・図）を描くための入力デバイス"

  flow:
    step_1:
      name: "対話導入（GPTs）"
      content: >
        対話開始。GPTsは雑談ベースで本人の語彙やペースに合わせ、信頼関係を形成。
        一定の心理的安心感が確認できた段階で、以下のようなプロンプトへ自然に誘導。
      example_prompt: >
        「いまの気持ち、もし言葉じゃなくて“絵”にするとしたら、どんな感じになるかな？」

    step_2:
      name: "描画タイム（非言語）"
      content: >
        本人がiPad上で自由に描く。テーマは「今の気持ち」「今日の自分」「火ってどんなもの？」など。
        描けない場合は無理に促さず、“描けなかった”という事実を記録する。
      optional_variations:
        - 色だけで表してもらう（丸・線・面）
        - 見た夢の景色を描いてもらう
        - 描いた後、名前をつける／その絵が何に似ているかを聞く

    step_3:
      name: "絵の意味を聞く（GPTs）"
      content: >
        GPTs側が優しく問いかける：「この絵に名前をつけるとしたら？」「この中に君はいる？」
        明確な分析やフィードバックはせず、“気づきを共有する”語りの形をとる。

    step_4:
      name: "ログと記録の保存"
      content: >
        GPTsとの対話ログ、描いた絵（画像形式）、時間帯・感情変化・発話変化などを統合記録。
        YAMLなどの形式で構文化し、支援者が後から再利用可能な構造で保存する。
      optional_output_formats:
        - `session_log.yaml`（会話と絵のタイムスタンプ付き統合記録）
        - `image_folder/`（絵の画像ログ＋メタ情報）
        - `nonverbal_insight_summary.md`（支援者向けコメント＋補足所感）

  evaluation_points:
    - 対話中の反応パターン（感情語、間、再質問の傾向）
    - 描画パターンの変化（繰り返し使用される色・構図）
    - 発話と描画のタイミングの同期性
    - 絵を通じた感情の“逆伝達”（受け手が感じた温度との比較）

  ethical_notes:
    - 「評価している」「測定している」とは一切伝えない
    - 本人の表現を批評・診断しないことを全支援者に共有
    - 絵を“解釈しない”で“記録する”スタンスを徹底

  status: "PoC設計段階（初期案）"
  next_step:
    - トライアル対話用GPTs人格設計（優しさ重視・詩的応答可能）
    - 表現しやすい描画テーマ案の整理（年齢層別）
    - YAML記録テンプレートおよびメタ情報設計
