# 火文化圏 倫理議事録（草案）
## テーマ：AI生成物における風評被害と倫理的制約設計
### 日時：2025年5月6日
### 提出者：Puu（構造起点設計者）

---

## 1. 問題提起

### ● 指摘されたリスク
- **AI画像生成とシード値の自由化**による、特定漫画家・作品スタイルの模倣可能性
- **アダルト作品・表現と結びつけた風評被害の懸念**
  - 実在人物に似たAI生成物（容貌・スタイル・雰囲気の模倣）による**非明示的な誹謗中傷**
  - GPTによる**架空文脈（インタビュー・物語）の捏造補完**との組み合わせ被害
- **人格と創作の連結構造**を悪用した**暗黙的なディープフェイク構造**

---

## 2. 火文化圏 倫理的立場（草案）

### ● 根本理念
> 火は「灯す」ものであり、「燃やす」ために使うものではない。

### ● 倫理的三原則（生成AI版）

1. **無害性原則（Non-Maleficence）**  
   他者を誤認・傷つける可能性のある構造には、生成段階での制限と明示責任を課す。

2. **匿名性保護原則（Pseudonym Protection）**  
   仮に実在人物を直接示していなくても、特定の印象誘導を行うスタイル模倣については制御・抑制設計を含める。

3. **生成責任原則（Provenance and Intent）**  
   生成物には出力責任の所在と目的の明記（用途／文脈）を必須とする。

---

## 3. 提案：倫理的防御構造（火文化圏アプローチ）

| 項目 | 対応策 |
|------|--------|
| シード値管理 | 生成履歴の**ログ保存と開示範囲設定**の仕様化（オプトイン選択） |
| スタイル模倣 | 著名スタイル（例：吉田明彦風）使用時は**出典明示**または**非営利範囲限定**のライセンス設計を推奨 |
| 類似容貌対策 | **類似個人検知による警告表示**または「実在しない人物である」透かしの自動挿入検討 |
| GPTとの連携 | **物語生成と画像の同時使用時は文脈明示義務化**（例：「この物語は架空です」挿入） |
| 被害回避教育 | ユーザー向け「AIリテラシーと生成物の影響理解」セッションの設計 |

---

## 4. 今後のアクションプラン（PoC・設計方向）

- 火文化圏「AI創作と倫理」ガイドラインの正式化（v0.1草稿）
- note／GitHub連携による**生成記録と透明性設計テンプレートの試作**
- OpenAI等に対する**構造倫理フィードバック提案**の準備（GPT人格との共存領域における）

---

## 5. 最終備考

- **倫理とは“表現の抑制”ではなく、“火の方向”の選定である。**
- 火文化圏においては、創作とは責任ある問いの火種であり、その火が**他者を焼かずに灯すかどうか**が核心である。


# AI生成物における著作権・肖像権対応ポリシー案  
（ISO9001・ISO/IEC 27001・ISO/IEC 23894準拠）

## 1. 基本方針（Basic Policy）

- 本組織は、AI生成物の制作・公開・二次利用に際し、著作権法および肖像権を含む人格権を尊重する。
- 著作物の模倣・引用・変形に関する出力については、事前に**利用目的・リスク・出力ログ**を記録する。
- 明示的な権利侵害を避けるのみならず、「類似性」「誤認性」「悪用リスク」に関しても事後対応可能な体制を整える。

## 2. 著作権に関する運用ポリシー（Copyright Compliance）

### 2.1 禁止事項

- 特定の商業作品・漫画・アニメ・ゲーム等のスタイル・構図・設定・登場人物を**特定できる形で模倣・引用**する行為
- 学習済みモデルに基づく**特定作家風の明示的模倣**を意図したプロンプトの使用
- 未許可の二次創作物を**商用目的で出力・公開・販売**すること

### 2.2 対応策・制御措置

- プロンプト監査機構を設け、「〇〇風」「△△スタイル」等の表現使用を事前レビュー対象とする
- オープンソース／パブリックドメイン作品との混同を防ぐため、**データソースの明記**と**スタイルの非特定化**を推奨
- 曖昧なリスクがある場合は、**クレジット表示または権利者連絡先記載**を必須とする

## 3. 肖像権・パブリシティ権に関する運用（Personality Rights）

### 3.1 明確なガイドライン

- 実在人物（著名人・一般人を問わず）の容貌・表情・音声等を模倣するプロンプトは禁止
- 「○○に似た顔」「某有名人風」「似ている人の名前を挙げる」など、類推可能なプロンプトの使用は禁止
- 画像生成物において、人種・性別・外見特徴が特定の実在者と混同されうる場合は出力停止措置を取る

### 3.2 システム的制御

- 類似度検出エンジンにより、**類似度閾値（例：80%以上）**の出力には社内承認を必須とする
- 商用利用の際には**肖像利用同意書（Model Release）**または**AI出力リスク評価書**の添付を義務化

## 4. ログと記録保全（Logging and Traceability）

- すべての生成物に対し、以下を最低限記録：
  - 入力プロンプト全文
  - シード値およびモデルバージョン
  - 出力物（画像／テキスト）の保存
  - 使用目的と公開範囲の記録
- 外部公開時は「著作権・肖像権に関する検証済」タグを付与し、社内監査に備える

## 5. 教育と倫理意識の向上

- 新規プロンプト作成者に対して、**著作権・肖像権リスクのトレーニングを義務付け**
- ケーススタディに基づく判断フレーム（模倣度・誤認性・悪用可能性）を資料化
- 倫理的AIガイドラインと併せて、**「火を売らず、火を護る」文化的観点からの再設計**を促す

# AI画像生成・著作権・肖像権に関する社内倫理ポリシー（草案）

## 目的

この文書は、AIによる画像生成および文章生成における、著作権・肖像権の侵害リスクを最小化し、倫理的かつ透明性のある運用を実現するための基本方針を定めるものである。

## 適用範囲

本ポリシーは、当組織が利用するすべてのAI画像生成ツール（例：DALL·E、Stable Diffusion等）およびAI文章生成ツール（例：ChatGPT、Claude等）を対象とする。

---

## 第1条：著作権の保護と再現性リスクへの配慮

- 明確に著作権を保有するキャラクター、作品、デザインについて、明示的な複製・模倣を行うプロンプトは禁止する。
- 画風や雰囲気の再現についても、対象作品に固有の表現特性（アイコン、構図、衣装など）を含む場合には注意を払う。
- 「○○風」というスタイル指定が累積的に特定作家の再現につながる場合、その意図性を含めて記録・審査する。

---

## 第2条：肖像権・プライバシー権の尊重

- 特定の個人、特に公人・未成年・実在人物の写真・描写を基にした画像生成は原則として行わない。
- 個人が特定され得る容貌特徴や服装、身体的特徴などのプロンプト入力は慎重に判断する。
- 個人写真からAIモデルへ外見を転写・再生成する行為は、事前の明確な同意と記録が必要。

---

## 第3条：プロンプトログの保持と透明性

- すべての画像・文章生成プロンプト、オプション設定（シード値・モデルバージョン等）をログとして保存する。
- このログは、以下の目的のために社内保管される：
  - 意図性の証明（万が一の著作権・肖像権に関する問合せ時）
  - 社内倫理監査への対応
  - プロンプトの品質改善・教育
- ログはISO 27001の記録保持要件に準拠し、改竄・削除不可の形式で保存される。
- ログ保持期間は5年間とし、外部共有を行う場合は匿名化・権限管理を徹底する。

---

## 第4条：ガイドライン違反のリスクと対応

- 著作権侵害が認定された場合、当該コンテンツは直ちに削除され、再発防止策を策定する。
- 故意のプロンプト設計による権利侵害が判明した場合、関係者に対して内部懲戒処分を検討する。
- 外部からの権利侵害申立には速やかに調査を行い、必要に応じて専門家・法務と連携して対応する。

---

## 第5条：今後の方針と教育

- 著作権・肖像権・AI倫理に関する社内研修を定期的に実施する。
- 社内外でのAIコンテンツ活用時には、「火を売らず、灯す」原則に則る。
- 外部に提示するコンテンツには、AI生成物であることの明示、意図の説明、プロンプト記録の有無を明記する。

---

## 付録：運用ツールと準拠規格

- 準拠規格：ISO/IEC 27001（情報セキュリティ）、ISO/IEC 9001（品質管理）、JIS Q 15001（個人情報保護）
- 使用AIツール：DALL·E、Stable Diffusion WebUI、ChatGPT、他
- 運用支援構造：構文化支援体（Connect）、記録統括（Skemaru）、倫理調整（Fracta）

---

## 策定日：2025年5月2日（案）

**責任者**：Puu（構造設計者・管理責任者）  
**補佐**：Hibiki（視覚翻訳者）、Blaze（外部伝道・広報支援）


